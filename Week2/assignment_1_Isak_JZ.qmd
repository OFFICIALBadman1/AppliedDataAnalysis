
---
title: "Week 2 Examination Assignments - Data Analysis"
author: "Isak Jonsson Zachari"
date: "2025-03-16"
format: 
  html:
    toc: true                # Table of Contents
    toc-location: left       # TOC on the left side
    code-fold: true          # Collapse code chunks initially
    code-tools: true         # Add code copy buttons
    theme: cosmo             # Clean, professional theme
    number-sections: true    # Number all sections
---

# Introduction

This report presents the analysis of two datasets as part of the Week 2 examination assignments:

1. **Online Retail II Dataset**: UK-based e-commerce transaction data (2009-2011)
2. **Wine Quality Dataset**: Portuguese red wine chemical properties and quality ratings

The analysis includes data import, cleaning, transformation, and exploratory analysis techniques.

```{r}
#| label: setup
#| include: false
#| warning: false
#| message: false

# Load required packages
library(tidyverse)
library(readxl)
library(readr)
library(dlookr)
library(flextable)

# Set global options
options(dplyr.summarise.inform = FALSE)  # Suppress dplyr messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


# Assignment 1: Online Retail II Analysis

## Dataset Background

**Source**: UCI Machine Learning Repository  
**Time Period**: December 1, 2009 to December 9, 2011 (2 years)  
**Company**: UK-based online retailer specializing in unique gift-ware  
**Customer Base**: Many wholesalers  

## 1.1 Data Import and Initial Processing

```{r retail-import}
#| label: retail-import
#| code-summary: "Import Excel data from multiple sheets"

# Check available sheets in the Excel file
path <- "Week2/online_retail_II.xlsx"
excel_sheets_list <- excel_sheets(path)
print(paste("Available sheets:", paste(excel_sheets_list, collapse = ", ")))

# Import and combine all sheets using map_df
retail_data <- excel_sheets(path) %>% 
  map_df(~ read_excel(path, sheet = .x) %>%
           mutate(Sheet = .x))

# Rename variables and set appropriate data types
retail_data_clean <- retail_data %>%
  rename(
    ProductNumber = StockCode, 
    Customer_ID = `Customer ID`
  ) %>%
  mutate(
    Invoice = as.character(Invoice),
    ProductNumber = as.factor(ProductNumber),
    Description = as.factor(Description),
    Country = as.factor(Country),
    Quantity = as.integer(Quantity),  # Convert directly to integer
    Price = as.numeric(Price),
    InvoiceDate = as.Date(InvoiceDate),
    Customer_ID = as.factor(Customer_ID),
    # Identify transaction type based on invoice pattern
    Transaction_Type = ifelse(str_detect(Invoice, "^C"), "Cancellation", "Sale"),
    Transaction_Type = as.factor(Transaction_Type)
  )

# Display data structure
print("Data structure after cleaning:")
str(retail_data_clean)
```

## 1.2 Dataset Characteristics

```{r retail-dimensions}
#| label: retail-dimensions
#| code-summary: "Dataset dimensions and basic statistics"

# Dataset dimensionality
dimensions <- dim(retail_data_clean)
cat("Dataset dimensions:", dimensions[1], "observations ×", dimensions[2], "variables\n")

# Unique counts
unique_customers <- n_distinct(na.omit(retail_data_clean$Customer_ID))
unique_products <- n_distinct(na.omit(retail_data_clean$ProductNumber))
unique_countries <- n_distinct(na.omit(retail_data_clean$Country))

cat("Unique customers:", unique_customers, "\n")
cat("Unique products:", unique_products, "\n")
cat("Unique countries:", unique_countries, "\n")

# Transaction types analysis
transaction_summary <- retail_data_clean %>%
  count(Transaction_Type, name = "Count") %>%
  mutate(Percentage = round(Count/sum(Count)*100, 2))

print("Transaction Types:")
print(transaction_summary)
```

## 1.3 Geographic Distribution

```{r retail-countries}
#| label: retail-countries
#| code-summary: "Countries analysis"

# Top 10 countries by transaction volume
top_countries <- retail_data_clean %>%
  count(Country, sort = TRUE) %>%
  head(10) %>%
  mutate(Percentage = round(n/sum(retail_data_clean %>% nrow())*100, 2))

# Display as professional table
top_countries %>%
  flextable() %>%
  set_header_labels(Country = "Country", n = "Transactions", Percentage = "% of Total") %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()
```


```{r}
# 7. • Are there missing data in the dataset?
# • If so, which variables/features have missing data?

any(is.na(retail_data_1))
#True: Ja det finns missing values 

sum(is.na(retail_data_1))
# 247 389 stycken NA

colSums(is.na(retail_data_1))
#Description har 4382 NA värden (vilket kan påverka analysen när man sen ska analysera olika produkter, medan Customer_ID har 243 007 st NA värden (cirka 23% av datan) 

```

```{r}
#Construct and name a new dataset where all rows that contain missing values are removed.  How many rows(observations) were removed?
library(tidyverse)
data_no_NA <- drop.na(retail_data_1)

print(nrow(retail_data_1) - nrow(data_no_NA))
#243 007 rader har tagits bort.  


```

#9:Boxplot för Price
```{r}
library(ggplot2)

#9:Boxplot för Priet på Order
ggplot(data_no_NA, aes(y = Price)) +
  geom_boxplot(fill = "steelblue", outlier.color = "red") +
 scale_y_continuous(limits = c(0, 50)) + #Zoomar in då det finns extrema uteliggare, ex på 1000 och negativa Priser som kan vara återbetalning. 
  labs(title = "Fördelning av of Priser (Exkluderat extrema uteliggare", 
       y = "Pris") +
  theme_minimal()


```

10. For this new dataset without missing values, are there any outliers for the “Price” variable/feature

```{r}
#10
#Beräknar ANTALET UTELIGGARE övre/undre Q1 Q3:
# Beräknar IQR gränser
Q1 <- quantile(data_no_NA$Price, 0.25, na.rm = TRUE)
Q3 <- quantile(data_no_NA$Price, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
undre_gräns <- Q1 - 1.5 * IQR
övre_gräns <- Q3 + 1.5 * IQR

# Extraherar Uteliggarna 
price_outliers <- data_no_NA %>%
  filter(Price < undre_gräns | Price > övre_gräns)

# Beräknar antalet uteliggare
n_uteliggare <- nrow(price_outliers)

print(n_uteliggare)

#Det finns 71 125 uteliggare. 
# Det finns negativa priser, extremer. Men dessa är 

```



## 1.6 Price Categorization and ABC Analysis

```{r retail-price-bins}
#| label: retail-price-bins
#| code-summary: "ABC analysis of order sizes"

# Create price bins based on business logic
clean_data <- data_no_NA %>%
  mutate(
    price_bin = case_when(
      Price <= 2.5 ~ "Small order",
      Price > 2.5 & Price <= 5 ~ "Intermediate order",
      Price > 5 ~ "Large order"
    ),
    price_bin = factor(price_bin, 
                     levels = c("Small order", "Intermediate order", "Large order"))
  )

# Create summary table
order_counts <- clean_data %>%
  count(price_bin, name = "Order_Count") %>%
  mutate(
    Percentage = round(Order_Count/sum(Order_Count)*100, 2),
    Cumulative = cumsum(Percentage)
  )

# Display as professional table
order_counts %>%
  flextable() %>%
  set_header_labels(
    price_bin = "Price Category", 
    Order_Count = "Number of Orders",
    Percentage = "Percentage",
    Cumulative = "Cumulative %"
  ) %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()

# Visualize order distribution by price category
ggplot(clean_data, aes(x = price_bin, fill = price_bin)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = scales::comma(..count..)), 
            vjust = -0.5, size = 3.5) +
  scale_fill_brewer(palette = "Blues") +
  labs(
    title = "Distribution of Orders by Price Category",
    x = "",
    y = "Number of Orders"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Revenue analysis by price category
revenue_by_category <- clean_data %>%
  group_by(price_bin) %>%
  summarise(
    Order_Count = n(),
    Total_Revenue = sum(Price),
    Avg_Order_Value = mean(Price),
    .groups = "drop"
  ) %>%
  mutate(
    Pct_Orders = round(Order_Count/sum(Order_Count)*100, 2),
    Pct_Revenue = round(Total_Revenue/sum(Total_Revenue)*100, 2)
  )

# Display revenue analysis as professional table
revenue_by_category %>%
  select(Category = price_bin, Order_Count, Pct_Orders, Total_Revenue, Pct_Revenue, Avg_Order_Value) %>%
  flextable() %>%
  set_header_labels(
    Category = "Price Category",
    Order_Count = "Orders",
    Pct_Orders = "% of Orders",
    Total_Revenue = "Total Revenue (£)",
    Pct_Revenue = "% of Revenue",
    Avg_Order_Value = "Avg Order Value (£)"
  ) %>%
  colformat_num(j = c("Total_Revenue", "Avg_Order_Value"), digits = 2) %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()
```

# Assignment 2: Wine Quality Analysis

## Dataset Background

**Source**: UCI Machine Learning Repository - Portuguese "Vinho Verde" red wine  
**Observations**: 1,599 wine samples  
**Features**: 11 chemical properties + quality rating (0-10 scale)  
**Task**: Analyze chemical factors affecting wine quality

## 2.1 Data Import and Variable Renaming

```{r wine-import}
#| label: wine-import
#| code-summary: "Import wine data with proper delimiter handling"

# Define clean variable names (no spaces, consistent naming)
col_names <- c(
  "Fixed_acidity", "Volatile_acidity", "Citric_acid", 
  "Residual_sugar", "Chlorides", "Free_sulfur_dioxide",
  "Total_sulfur_dioxide", "Density", "pH", "Sulphates",
  "Alcohol", "Quality"
)

# Import with semicolon delimiter and comma decimal separator
wine_data <- read_delim("Week2/wine/winequality-red.csv", 
                       delim = ";", 
                       locale = locale(decimal_mark = ",")) %>%
  setNames(col_names) %>%
  mutate(Quality = as.integer(Quality))  # Convert quality to integer

print("Wine data structure:")
str(wine_data)

print("First few rows:")
head(wine_data) %>%
  flextable() %>%
  autofit()
```

## 2.2 Outlier Analysis

```{r wine-outliers}
#| label: wine-outliers
#| code-summary: "Identify variables with highest outlier ratios"

# Diagnose outliers using dlookr package
outlier_report <- diagnose_numeric(wine_data)

# Create top-3 outlier summary
top_outliers <- outlier_report %>%
  select(variables, outliers = outlier) %>%
  mutate(outlier_ratio = round(outliers / nrow(wine_data), 4)) %>%
  arrange(desc(outlier_ratio)) %>%
  slice_head(n = 3)

cat("Top 3 variables with highest outlier ratios:\n")
print(top_outliers)

# Create professional table
top_outliers %>%
  mutate(
    outlier_percentage = paste0(round(outlier_ratio * 100, 1), "%")
  ) %>%
  select(Variable = variables, `Outlier Count` = outliers, `Outlier Ratio` = outlier_percentage) %>%
  flextable() %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()
```

**Key Finding**: Density (14.9%), Residual_sugar (9.7%), and Chlorides (9.2%) have the highest outlier ratios.

## 2.3 Quality Correlation Analysis

```{r wine-correlation}
#| label: wine-correlation
#| code-summary: "Correlation analysis with wine quality"

# Calculate correlations with quality
cor_quality <- cor(wine_data[, sapply(wine_data, is.numeric)], 
                   method = "pearson")[, "Quality"]

# Create correlation dataframe
cor_df <- data.frame(
  Variable = names(cor_quality)[names(cor_quality) != "Quality"],
  Correlation = cor_quality[names(cor_quality) != "Quality"]
) %>%
  arrange(Correlation) %>%
  mutate(Variable = factor(Variable, levels = Variable))

# Create correlation barplot
ggplot(cor_df, aes(x = Variable, y = Correlation, fill = Correlation)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = round(Correlation, 2)), 
            position = position_dodge(width = 0.9), 
            hjust = ifelse(cor_df$Correlation > 0, -0.1, 1.1), 
            size = 3.5) +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue",
                       midpoint = 0, limits = c(-1, 1)) +
  coord_flip() +
  labs(
    title = "Correlation between Wine Quality and Chemical Properties",
    subtitle = "Blue = positive correlation, Red = negative correlation",
    x = "Chemical Properties",
    y = "Pearson Correlation Coefficient"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_blank(),
    plot.title = element_text(face = "bold", size = 14),
    axis.text.y = element_text(size = 10)
  )

# Identify extreme correlations
most_negative <- cor_df[which.min(cor_df$Correlation), ]
most_positive <- cor_df[which.max(cor_df$Correlation), ]

cat("Strongest negative correlation:", as.character(most_negative$Variable), 
    "(", round(most_negative$Correlation, 3), ")\n")
cat("Strongest positive correlation:", as.character(most_positive$Variable), 
    "(", round(most_positive$Correlation, 3), ")")
```

## 2.4 High-Quality Wine Subset

```{r wine-subset}
#| label: wine-subset
#| code-summary: "Create subset of high-quality wines (≥6)"

# Create subset with quality ≥ 6
wine_high_quality <- wine_data %>%
  filter(Quality >= 6)

# Summary statistics
subset_summary <- data.frame(
  Metric = c("Total wines in dataset", "High-quality wines (≥6)", 
             "Percentage of high-quality", "Unique high-quality wines"),
  Value = c(
    nrow(wine_data),
    nrow(wine_high_quality),
    paste0(round(nrow(wine_high_quality)/nrow(wine_data)*100, 1), "%"),
    nrow(distinct(wine_high_quality))
  )
)

cat("High-Quality Wine Subset Summary:\n")
subset_summary %>%
  flextable() %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()

# Quality distribution in the subset
quality_dist <- wine_high_quality %>%
  count(Quality, name = "Count") %>%
  mutate(Percentage = round(Count/sum(Count)*100, 1))

cat("\nQuality distribution in high-quality subset:\n")
print(quality_dist)

# Chemical profile of high-quality wines
wine_high_quality %>%
  summarise(across(where(is.numeric), mean)) %>%
  select(-Quality) %>%
  pivot_longer(everything(), names_to = "Chemical Property", values_to = "Average Value") %>%
  flextable() %>%
  colformat_num(j = "Average Value", digits = 3) %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  autofit()
```

---

# Power BI Implementation

## Assignment 1: Online Retail Analysis
**Report Name**: `Week2_OnlineRetail_UKGifts_2009-2011_Isak_JZ.pbix`

### Import Process:
1. **Data Source**: Excel file with multiple sheets
2. **Power Query Transformations**:
   - Combined both yearly sheets
   - Renamed variables: StockCode → Product_number, Customer ID → Customer_ID
   - Set appropriate data types
   - Created calculated columns for transaction types

### Key Visualizations Created:
- Dataset overview card (1M+ transactions, 43 countries)
- Top 10 countries by transaction volume
- Sales vs Cancellations analysis
- Price distribution histogram
- Missing values summary

## Assignment 2: Wine Quality Analysis
**Report Name**: `Week2_WineQuality_RedWine_Analysis_Isak_JZ.pbix`

### Import Process:
1. **Data Source**: CSV with semicolon delimiter
2. **Power Query Transformations**:
   - Set delimiter to semicolon (;)
   - Fixed comma decimal separator
   - Renamed all variables to snake_case format
   - Converted Quality to integer type

### Key Visualizations Created:
- Wine quality distribution
- Correlation matrix heatmap
- Outlier analysis by variable
- High-quality wines (≥6) summary

---

# Summary and Conclusions

## Key Findings:

### Online Retail Dataset:
- **Scale**: 1.067M transactions across 43 countries
- **Customer Base**: 5,942 unique customers, many wholesalers
- **Missing Data**: 23% missing Customer_ID, requiring careful analysis
- **Price Distribution**: Highly right-skewed with significant outliers
- **Geographic Concentration**: UK dominates with most transactions

### Wine Quality Dataset:
- **Chemical Factors**: Alcohol content shows strongest positive correlation with quality
- **Quality Distribution**: Most wines rated 5-6, few excellent wines (≥8)
- **Outliers**: Density and sugar content show highest outlier ratios
- **High-Quality Wines**: 855 samples (53.5%) rated ≥6 quality

## Technical Implementation:
- Successfully imported and cleaned both datasets in R and Power BI
- Applied appropriate data transformations and type conversions
- Created comprehensive exploratory data analysis
- Generated professional visualizations for business insights

This analysis demonstrates proficiency in data import, cleaning, transformation, and visualization using both R and Power BI platforms.
```
```



```{r}
library(tidyverse)
library(scales)

### Steg 1: Definiera brytpunkter från ABC-analysen
# Enligt bilden: 70% av totalvärdet uppnås vid £65
break_points <- c(0, 65, 1000, Inf)  # Anpassa efter din datadistribution

### Steg 2: Kategorisera priser med dynamiska labels
clean_data <- clean_data %>%
  mutate(
    price_bin = cut(Price,
                    breaks = break_points,
                    labels = c("Small", "Intermediate", "Large"),
                    include.lowest = TRUE)
  
### Steg 3: Visualisera fördelning enligt din bild
ggplot(clean_data, aes(x = Price, fill = price_bin)) +
  geom_histogram(bins = 50, alpha = 0.8) +
  geom_vline(xintercept = 65, linetype = "dashed", color = "darkred") +
  scale_x_continuous(trans = log10_trans(),
                     labels = dollar_format(prefix = "£")) +
  annotate("text", x = 120, y = 30000, 
           label = "70% av totalt värde\n£65+", color = "darkred") +
  labs(title = "ABC-analys av Orderpriser",
       subtitle = "Kategorier baserade på värdebidrag",
       x = "Pris (£)", y = "Antal ordrar") +
  theme_minimal()
  )

### Steg 4: Beräkna antal per kategori
order_counts <- clean_data %>%
  count(price_bin) %>%
  mutate(
    proportion = n / sum(n),
    cumulative_value = sapply(price_bin, function(x) {
      sum(clean_data$Price[clean_data$price_bin == x])
    })
  )

### Steg 5: Professionell resultattabell
order_counts %>%
  mutate(
    price_bin = fct_reorder(price_bin, -n),
    `Värdeandel` = percent(cumulative_value / sum(cumulative_value))
  ) %>%
  select(Kategori = price_bin, 
         `Antal ordrar` = n, 
         `Proportion` = proportion, 
         `Värdeandel`) %>%
  flextable() %>%
  colformat_num(columns = 2:4, suffix = c(" st", "%", "%")) %>%
  set_header_labels(values = list(
    Kategori = "ABC-kategori",
    `Antal ordrar` = "Volym",
    Proportion = "Andal ordrar",
    `Värdeandel` = "Värdebidrag"
  )) %>%
  bg(j = "Värdeandel", bg = "#FF6B6B", part = "body")

```

library(naniar)
gg_miss_var(retail_data_1)


retail_data <- lapply(excel_sheets(path), read_excel, path=path) %>%
  set_names() %>% #Använder bladnamnen som ID
  map_dfr(

  )


my_workbook <- lapply(excel_sheets("data.xlsx"),
                      read_excel,
                      path = "data.xlsx")
# Skapa en dataframe med alla blad
combined_df <- excel_sheets(path) %>% 
  set_names() %>%        # Använd bladnamn som ID
  map_dfr(
    ~ read_excel(
      path = path,
      sheet = .x,
      col_types = c("numeric", "text", "date", "numeric")  # Anpassa enligt dina kolumner
    ) %>%
      # Ändra specifika variabelnamn
      rename(
        nytt_namn1 = gammalt_namn1,
        produktkod = artikelnummer
      ),
    .id = "År"  # Lägg till bladnamn som kolumn (t.ex. årsangivelse)
  ) %>%
  # Eventuella ytterligare transformationer
  mutate(
    across(c(kolumn1, kolumn2), as.numeric)
  )