
---
title: "Week 2 Examination Assignments - Data Analysis"
author: "Isak Jonsson Zachari"
date: "2025-08-29"
format:
  html:
    toc: true                # Table of Contents
    toc-location: left       # TOC on the left side
    code-fold: true          # Collapse code chunks initially
    code-tools: true         # Add code copy buttons
    theme: cosmo             # Clean, professional theme
    number-sections: true    # Number all sections
---

# Introduction

This report presents the analysis of two datasets as part of the Week 2 examination assignments:

1. **Online Retail II Dataset**: UK-based e-commerce transaction data (2009-2011)
2. **Wine Quality Dataset**: Portuguese red wine chemical properties and quality ratings

The analysis includes data import, cleaning, transformation, and exploratory analysis techniques.

```{r}
pkgs <- c("readr", "tidyverse", "dlookr", "flextable", "tinytex", "classInt")
for (i in pkgs){
    if(! i %in% installed.packages()){
        install.packages(i, dependencies = TRUE)}
    require(i) }
```

```{r}
#| label: setup
#| include: false
#| warning: false
#| message: false

# Load required packages
library(tidyverse)
library(readxl)
library(readr)
library(dlookr)
library(flextable)

# Set global options
options(dplyr.summarise.inform = FALSE)  # Suppress dplyr messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


# Assignment 1: Online Retail II Analysis

## Dataset Background

**Source**: UCI Machine Learning Repository
**Time Period**: December 1, 2009 to December 9, 2011 (2 years)
**Company**: UK-based online retailer specializing in unique gift-ware
**Customer Base**: Many wholesalers

## 1.1 Data Import and Initial Processing

```{r retail-import}
#| label: retail-import
#| code-summary: "Import Excel data from multiple sheets"

# Check available sheets in the Excel file
path <- "Week2/online_retail_II.xlsx"
excel_sheets_list <- excel_sheets(path)
print(paste("Available sheets:", paste(excel_sheets_list, collapse = ", ")))

# Import and combine all sheets using map_df
retail_data <- excel_sheets(path) %>%
  map_df(~ read_excel(path, sheet = .x) %>%
           mutate(Sheet = .x))

# Rename variables and set appropriate data types
retail_data_clean <- retail_data %>%
  rename(
    ProductNumber = StockCode,
    Customer_ID = `Customer ID`
  ) %>%
  mutate(
    Invoice = as.character(Invoice),
    ProductNumber = as.factor(ProductNumber),
    Description = as.factor(Description),
    Country = as.factor(Country),
    Quantity = as.integer(Quantity),  # Convert directly to integer
    Price = as.numeric(Price),
    InvoiceDate = as.Date(InvoiceDate),
    Customer_ID = as.factor(Customer_ID),
    # Identify transaction type based on invoice pattern
    Transaction_Type = ifelse(str_detect(Invoice, "^C"), "Cancellation", "Sale"),
    Transaction_Type = as.factor(Transaction_Type)
  )

# Display data structure
print("Data structure after cleaning:")
str(retail_data_clean)
```

## 1.2 Dataset Characteristics

```{r retail-dimensions}
#| label: retail-dimensions
#| code-summary: "Dataset dimensions and basic statistics"

# Dataset dimensionality
dimensions <- dim(retail_data_clean)
cat("Dataset dimensions:", dimensions[1], "observations ×", dimensions[2], "variables\n")

# Unique counts
unique_customers <- n_distinct(na.omit(retail_data_clean$Customer_ID))
unique_products <- n_distinct(na.omit(retail_data_clean$ProductNumber))
unique_countries <- n_distinct(na.omit(retail_data_clean$Country))

cat("Unique customers:", unique_customers, "\n")
cat("Unique products:", unique_products, "\n")
cat("Unique countries:", unique_countries, "\n")

# Transaction types analysis
transaction_summary <- retail_data_clean %>%
  count(Transaction_Type, name = "Count") %>%
  mutate(Percentage = round(Count/sum(Count)*100, 2))

print("Transaction Types:")
print(transaction_summary)
```

## 1.3 Geographic Distribution

```{r retail-countries}
#| label: retail-countries
#| code-summary: "Countries analysis"
#|
# Top 10 countries by transaction volume
top_countries <- retail_data_clean %>%
  count(Country, sort = TRUE) %>%
  head(10) %>%
  mutate(Percentage = round(n/sum(retail_data_clean %>% nrow())*100, 2))

# Display as professional table
top_countries %>%
  flextable() %>%
  set_header_labels(Country = "Country", n = "Transactions", Percentage = "% of Total") %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()
```


```{r}
# 7. • Are there missing data in the dataset?
# • If so, which variables/features have missing data?

any(is.na(retail_data_clean))
#True: Ja det finns missing values

sum(is.na(retail_data_clean))
# 247 389 stycken NA

colSums(is.na(retail_data_clean))
#Description har 4382 NA värden (vilket kan påverka analysen när man sen ska analysera olika produkter, medan Customer_ID har 243 007 st NA värden (cirka 23% av datan)

```

```{r}
#Construct and name a new dataset where all rows that contain missing values are removed.  How many rows(observations) were removed?
library(tidyverse)
data_no_NA <- drop_na(retail_data_clean)

print(nrow(retail_data_clean) - nrow(data_no_NA))
#243 007 rows where removed


```

#9:Boxplot för Price
```{r}
library(ggplot2)

#9:Boxplot för Priet på Order
ggplot(data_no_NA, aes(y = Price)) +
  geom_boxplot(fill = "steelblue", outlier.color = "red") +
 scale_y_continuous(limits = c(0, 50)) + #Zoomar in då det finns extrema uteliggare, ex på 1000 och negativa Priser som kan vara återbetalning.
  labs(title = "Distribution of proce (exdluded extremt outliers",
       y = "Pris") +
  theme_minimal()


```

10. For this new dataset without missing values, are there any outliers for the “Price” variable/feature

```{r}
#10
#Beräknar ANTALET UTELIGGARE övre/undre Q1 Q3:
# Beräknar IQR gränser
Q1 <- quantile(data_no_NA$Price, 0.25, na.rm = TRUE)
Q3 <- quantile(data_no_NA$Price, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
undre_gräns <- Q1 - 1.5 * IQR
övre_gräns <- Q3 + 1.5 * IQR

# Extraherar Uteliggarna
price_outliers <- data_no_NA %>%
  filter(Price < undre_gräns | Price > övre_gräns)

# Beräknar antalet uteliggare
n_uteliggare <- nrow(price_outliers)

print(n_uteliggare)

#Det finns 71 125 uteliggare.
# Det finns negativa priser, extremer

```



## 1.6 Price Categorization and ABC Analysis

```{r retail-price-bins}
#| label: retail-price-bins
#| code-summary: "ABC analysis of order sizes"

# Create price bins based on business logic
clean_data <- data_no_NA %>%
  mutate(
    price_bin = case_when(
      Price <= 2.5 ~ "Small order",
      Price > 2.5 & Price <= 5 ~ "Intermediate order",
      Price > 5 ~ "Large order"
    ),
    price_bin = factor(price_bin,
                     levels = c("Small order", "Intermediate order", "Large order"))
  )

# Create summary table
order_counts <- clean_data %>%
  count(price_bin, name = "Order_Count") %>%
  mutate(
    Percentage = round(Order_Count/sum(Order_Count)*100, 2),
    Cumulative = cumsum(Percentage)
  )


# Small orders (≤£2.5)**: 59.83% of all orders - the majority!
# Intermediate orders (£2.5-5)**: 26.06% of orders
# Large orders (>£5)**: Only 14.11% of orders


# Display as professional table
order_counts %>%
  flextable() %>%
  set_header_labels(
    price_bin = "Price Category",
    Order_Count = "Number of Orders",
    Percentage = "Percentage",
    Cumulative = "Cumulative %"
  ) %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()

# Visualize order distribution by price category
ggplot(clean_data, aes(x = price_bin, fill = price_bin)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = scales::comma(..count..)),
            vjust = -0.5, size = 3.5) +
  scale_fill_brewer(palette = "Blues") +
  labs(
    title = "Distribution of Orders by Price Category",
    x = "",
    y = "Number of Orders"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Revenue analysis by price category
revenue_by_category <- clean_data %>%
  group_by(price_bin) %>%
  summarise(
    Order_Count = n(),
    Total_Revenue = sum(Price),
    Avg_Order_Value = mean(Price),
    .groups = "drop"
  ) %>%
  mutate(
    Pct_Orders = round(Order_Count/sum(Order_Count)*100, 2),
    Pct_Revenue = round(Total_Revenue/sum(Total_Revenue)*100, 2)
  )

# Display revenue analysis as professional table
revenue_by_category %>%
  select(Category = price_bin, Order_Count, Pct_Orders, Total_Revenue, Pct_Revenue, Avg_Order_Value) %>%
  flextable() %>%
  set_header_labels(
    Category = "Price Category",
    Order_Count = "Orders",
    Pct_Orders = "% of Orders",
    Total_Revenue = "Total Revenue (£)",
    Pct_Revenue = "% of Revenue",
    Avg_Order_Value = "Avg Order Value (£)"
  ) %>%
  colformat_num(j = c("Total_Revenue", "Avg_Order_Value"), digits = 2) %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()
```


Summary:
##  80/20 rule.
14.11% of orders (Large) → 54.28% of revenue
40.17% of orders (Int+Large) → 79.55% of revenue
##

#### ** Recommendations:**
1. **Focus on Large Orders (Category A)**
    - These customers generate 4x more revenue per order (£14.15 vs £1.26)
    - Priority customer service and retention programs
    - Premium shipping options

2. **Optimize Small Orders (Category C)**
    - High volume but low value - optimize for efficiency
    - Automated processing systems
    - Bundle offers to increase order size

3. **Nurture Intermediate Orders (Category B)**
    - Growth opportunity - encourage upselling to large order category
    - Targeted marketing campaigns



# Assignment 2: Wine Quality Analysis

## Dataset Background

**Source**: UCI Machine Learning Repository - Portuguese "Vinho Verde" red wine
**Observations**: 1,599 wine samples
**Features**: 11 chemical properties + quality rating (0-10 scale)
**Task**: Analyze chemical factors affecting wine quality

## 2.1 Data Import and Variable Renaming

```{r wine-import}
# Load required packages
library(tidyverse)
library(readr)
library(dlookr)
library(flextable)
library(corrplot)

# Task 1: Import dataset (Power BI )
# Task 2: Import into R with correct delimiter and data types

# Define clean variable names (no spaces, consistent naming)
col_names <- c(
  "fixed_acidity", "volatile_acidity", "citric_acid",
  "residual_sugar", "chlorides", "free_sulfur_dioxide",
  "total_sulfur_dioxide", "density", "pH", "sulphates",
  "alcohol", "quality"
)

# Import with semicolon delimiter and comma decimal separator (Task 2)
wine_data <- read_delim("Week2/wine/winequality-red.csv",
                       delim = ";",
                       locale = locale(decimal_mark = ",")) %>%
  setNames(col_names) %>%
  mutate(quality = as.integer(quality))  # Convert quality to integer

print("Wine data structure:")
str(wine_data)

# Task 3: Variable names done
# All variables now have clean names without spaces


```

## 2.2 Outlier Analysis

```{r wine-outliers}
# Task 4: Diagnose outliers - Top 3 variables
outlier_report <- diagnose_numeric(wine_data)

top_outliers <- outlier_report %>%
  select(variables, outliers = outlier) %>%
  mutate(outlier_ratio = round(outliers / nrow(wine_data), 4)) %>%
  arrange(desc(outlier_ratio)) %>%
  slice_head(n = 3)

cat("Task 4 - Top 3 variables with highest outlier ratios:\n")
print(top_outliers)

# Professional table for outliers
top_outliers %>%
  mutate(outlier_percentage = paste0(round(outlier_ratio * 100, 1), "%")) %>%
  select(Variable = variables, `Outlier Count` = outliers, `Outlier Ratio` = outlier_percentage) %>%
  flextable() %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()

```

**Key Finding**: density (14.9%), residual_sugar (9.7%), and  chlorides (9.2%) have the highest outlier ratios.

## 2.3 Quality Correlation Analysis

```{r wine-correlation}
# Task 5: Correlation analysis with quality
cor_quality <- cor(wine_data[, sapply(wine_data, is.numeric)],
                   method = "pearson")[, "quality"]

# Create correlation dataframe
cor_df <- data.frame(
  Variable = names(cor_quality)[names(cor_quality) != "quality"],
  Correlation = cor_quality[names(cor_quality) != "quality"]
) %>%
  arrange(Correlation) %>%
  mutate(Variable = factor(Variable, levels = Variable))

# Create correlation barplot (Creative visualization)
correlation_plot <- ggplot(cor_df, aes(x = Variable, y = Correlation, fill = Correlation)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = round(Correlation, 2)),
            position = position_dodge(width = 0.9),
            hjust = ifelse(cor_df$Correlation > 0, -0.1, 1.1),
            size = 3.5) +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue",
                       midpoint = 0, limits = c(-1, 1)) +
  coord_flip() +
  labs(
    title = "Correlation between Wine Quality and Chemical Properties",
    subtitle = "Blue = positive correlation, Red = negative correlation",
    x = "Chemical Properties",
    y = "Pearson Correlation Coefficient"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    panel.grid.major.y = element_blank(),
    plot.title = element_text(face = "bold", size = 14),
    axis.text.y = element_text(size = 10)
  )

print(correlation_plot)

# Find extreme correlations
most_negative <- cor_df[which.min(cor_df$Correlation), ]
most_positive <- cor_df[which.max(cor_df$Correlation), ]

cat("\nTask 5 - Correlation Results:\n")
cat("Most strongly NEGATIVELY correlated:", as.character(most_negative$Variable),
    "(", round(most_negative$Correlation, 3), ")\n")
cat("Most strongly POSITIVELY correlated:", as.character(most_positive$Variable),
    "(", round(most_positive$Correlation, 3), ")\n")

```


# Most strongly NEGATIVELY correlated: volatile_acidity ( -0,391 )

# Most strongly POSITIVELY correlated: alcohol ( 0.476 )

- **Quality Distribution**: Most wines are average (quality 5-6)
- **Key Quality Drivers**:
    - ↑ Alcohol content = ↑ Quality
    - ↓ Volatile acidity = ↑ Quality

- **Data Quality**: 14.9% density outliers suggest measurement issues
- **Premium Segment**: Only 2.1% achieve top quality (8/10)



## 2.4 High-Quality Wine Subset

```{r wine-subset}
# Task 6: Create subset with quality ≥ 6
wine_high_quality <- wine_data %>%
  filter(quality >= 6)

# Summary statistics
total_wines <- nrow(wine_data)
high_quality_count <- nrow(wine_high_quality)
percentage_high_quality <- round(high_quality_count / total_wines * 100, 1)

cat("\nTask 6 - High Quality Wine Subset:\n")
cat("Total wines in dataset:", total_wines, "\n")
cat("Wines with quality ≥ 6:", high_quality_count, "\n")
cat("Percentage of high-quality wines:", percentage_high_quality, "%\n")

# Quality distribution in the subset
quality_distribution <- wine_high_quality %>%
  count(quality, name = "Count") %>%
  mutate(Percentage = round(Count/sum(Count)*100, 1))

cat("\nQuality distribution in high-quality subset:\n")
print(quality_distribution)

# Create summary table for high-quality wines
summary_table <- data.frame(
  Metric = c("Total wines", "High-quality wines (≥6)", "Percentage", "Unique wines"),
  Value = c(
    total_wines,
    high_quality_count,
    paste0(percentage_high_quality, "%"),
    nrow(distinct(wine_high_quality))
  )
)

summary_table %>%
  flextable() %>%
  bg(part = "header", bg = "#2C3E50") %>%
  color(part = "header", color = "white") %>%
  align(align = "center", part = "all") %>%
  autofit()

```

---

# Key Findings

## Assignment 1: Online Retail II Analysis

### **Dataset Characteristics**
- **Scale**: 1,067,371 transactions across 43 countries over 2 years (2009-2011)
- **Customer Base**: 5,942 unique customers with 4,312 unique products
- **Geographic Distribution**: UK-dominated (85%+ of transactions) with significant international presence


### **Data Quality Issues**
- **Missing Values**: 243,007 rows (23%) contain missing data
  - customer_id: 243,007 missing (likely guest checkouts)
  - Description: 4,382 missing (product catalog gaps)
- **Price Outliers**: 71,125 outliers detected, including negative prices (returns/refunds)

### **Business Intelligence: ABC Analysis**
Following the **Pareto Principle (80/20 Rule)**:
- **Small Orders (≤£2.5)**: 59.83% of transactions → 20.44% of revenue
- **Intermediate Orders (£2.5-5)**: 26.06% of transactions → 25.27% of revenue
- **Large Orders (>£5)**: 14.11% of transactions → **54.28% of revenue**

**Critical Insight**: Just 14% of orders generate over half the revenue, confirming classic wholesale behavior.

### **Strategic Implications**
1. **Revenue Concentration**: Focus retention efforts on large order customers (£14.15 avg value)
2. **Operational Efficiency**: Optimize small order processing (high volume, low margin)
3. **Growth Opportunity**: Upsell intermediate customers toward large order category

---

## Assignment 2: Wine Quality Analysis

### **Chemical Quality Drivers**
**Strongest Correlations with Wine Quality:**
- **Positive**: Alcohol content (+0.476) - Higher alcohol = Better quality
- **Negative**: Volatile acidity (-0.391) - Lower acetic acid = Better quality

### **Data Distribution Insights**
- **Quality Scale**: Most wines rated 5-6 (average), few premium wines (quality ≥8: only 2.1%)
- **High-Quality Segment**: 855 wines (53.5%) achieve quality ≥6
- **Outlier Variables**: Density (14.9%), residual sugar (9.7%), chlorides (9.2%)

### **Wine Production Implications**
1. **Alcohol Management**: Higher alcohol content correlates with perceived quality
2. **Acidity Control**: Managing volatile acidity is crucial for quality improvement
3. **Quality Distribution**: Natural bell curve with few exceptional wines
